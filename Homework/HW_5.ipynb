{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5\n",
    "\n",
    "* Due on **Friday, Mar-20-2020**\n",
    "* Please comment your code and send it to our TA Ms Hangyu Liu (hangyu@hku.hk) \n",
    "* NOTE: Label your figures properly with comments in your code, that's **5%** of your total grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GDP versus Life expectancy (20%)\n",
    "\n",
    "- Download the data file named gdp_life.csv from Moodle\n",
    "- Load the data file into a Pandas data Frame using the read_csv() function\n",
    "- Make histograms of GDP and Life Exp to see what the data distributions look like, do they make sense to you?\n",
    "- Remove all the rows with NaNs\n",
    "- Remove the outliers in your dataset if necessary\n",
    "- Now look at the example of data filtering in Pandas data frames (see the \"Asia\" plot example in lecture notes/notebooks) make a similar bubble plot of GDP versus Life Exp as you've done in HW4 with all the continents, by setting the size of the bubbles using the population and the color of the bubbles using the continent: \n",
    "    - Asia (red)\n",
    "    - Europe (blue)\n",
    "    - Africa (green)\n",
    "    - North America (yellow)\n",
    "- NOTE: Use a **for**-loop to generate the bubble plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Earthquakes (20%)\n",
    "\n",
    "- load the data file \"Eq_last5Years.csv\", use the .head() function to take a first look at the data file.\n",
    "- print out the column index using the .columns attribute of your data frame (so you know what names to use for column access!)\n",
    "- make two histograms (use subplot() to generate a left and a right panel) to show the distributions of depth and magnitude of all the earthquakes in the last five years. Play with the plt.yscale() function and choose a proper axis scale to visualize the results.\n",
    "- plot the depth all the measured earthquakes as a function of magnitude, is there a connection between the two quantites? \n",
    "- Use the \"hammer\" projection, to show the locations of all the shallow earthquakes with depth less than 70 km. What are the geological indications of these locations? \n",
    "- Now plot all the deep earthquakes with depth greater than 450 km, what are the geological indications of these locations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Seismology, P-waves and S-waves (20%)\n",
    "\n",
    "The farther away an earthquake is from a receiver, the more time there is between the arrivals of the P and S waves.  This makes sense if you think about racing a little kid (who is on a tricycle) around a track.  The distance between you will just keep increasing as you run because the kid on the trike is slower (like the S wave). [Well, until you lap the little tyke.] \n",
    "\n",
    "You can use the difference between the arrival times of the two waves to calculate the distance to the earthquake source, if we know the velocities of the waves through the Earth.  So first we need to know how these two waves behave.  \n",
    "\n",
    "There are plenty of data on earthquakes and the arrival times of different waves. Here is a short video demonstration. \n",
    "\n",
    "https://www.iris.edu/hq/inclass/animation/traveltime_curves_how_they_are_created  \n",
    "\n",
    "- Download the data file \"SP_DeltaTime.txt\" and load it into Python as a data frame using the pandas function .read_csv(). _NOTE_:\n",
    "   - We need to skip the first two rows. We use the keyword argument **skiprows=2** in the read_csv() function to do that. \n",
    "   - **pd.read_csv( )** reads 'comma separated variables' by default but this file is _whitespace_ delimited. _whitespace_ is either spaces or tabs.   The keyword argument **delim_whitespace=True** will split on white space.\n",
    "- Use the head() function to take a look at what datasets are included in the data frame. We see that the  columns of **DeltaTimeData**  are: \n",
    "    - \"Deg\": the degrees away from the source (the angle from the center of the Earth)\n",
    "    - \"M\": the time of the P wave arrival in minutes\n",
    "    - \"S\": the  P wave arrival in seconds\n",
    "    - \"M.1\": the difference in the P and S wave arrival time in  minutes and \n",
    "    - \"S.1\" is same interval in seconds.  \n",
    "- Change the column names to be \"Degrees\", \"P_wave_minutes\", \"P_wave_seconds\", \"S-P_minutes\", \"S-P_seconds\"\n",
    "- What we really want for calculating the seismology is the arrival time in **decimal minutes**, not  minutes and seconds as in this data file.  Now defining a new column called \"P_decimal_minutes\" by converting the seconds data to decimal minutes (divide by 60) and add that to the minutes. \n",
    "- Now create another new column called \"S-P_decimal_minutes\" using the \"S-P_minutes\" and \"S-P_seconds\" based on the above converting algorithm\n",
    "- Now create another new column called \"S_decimal_minutes\", which is basically the sum of \"P_decimal_minutes\" and \"S-P_decimal_minutes\" (the P-wave arrival time + the S-P differential time)\n",
    "- Using your new data frame, plot the \"Degrees\" as a function of \"P_decimal_minutes\", and also plot the \"Degrees\" as a function of \"S_decimal_minutes\"\n",
    "- Which waves travel faster? Estimate the mean speed for the P-waves and S-waves\n",
    "- **[Extra Credit (10%)]** Calculate wave speeds of P-wave and S-wave as a function of time, make a separate plot to show it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Typhoons in 2018 (40%)\n",
    "\n",
    "- Download all the datasets for the Typhoons in 2018 from Moodle (the **TyphoonData** folder) to you own computer\n",
    "- The Typhoon **Jongdari** (Typhoon201812_JONGDARI.xlsx) had a very weird path, load the Typhoon Jongdari data into Python use Pandas, and plot the track of the Typhoon Jongdari on a **local map projection** with a black line\n",
    "- On top of the black track line, add a bubble plot of the path colored by it's \"Class\": 2(blue), 3(green), 4(yellow), 5(red), 6(magenda)\n",
    "- Now start a new figure, use the _glob_ module together with a _for_-loop to go through all the Excel files in the \"TyphoonData\" folder you've downloaded from Moodle. Show the tracks of all the Typhoons in 2018 **in one figure** using the **Orthographic Projection** of the Earth (no need to color it by it's Class, you can try that though, I'll give you 5% extra if you do so). Mark the starting point of each Typhoon using a star (marker = \"*\"), and mark the end points of each Typhoon using a plus sign (marker = \"+\")\n",
    "- Calculate the variable \"gradP\" (you've already used it in your in-class practice), which is the absolute pressure difference between the measured pressure and the maximum pressure, make a scatter plot showing the relationship between gradP and Wind speed in all the Typhoons (HINT: use the glob module to step through all the data files). Make sure you clean the datasets by removing all the outliers in the wind speed (there are zeros in the Wind data, these are invalid wind measurements).\n",
    "- **[Extra Credit (10%)]** What's the minimum, maximum and median latitude of the starting points of all the Typhoons? What about the same information for the Pressure and Wind speed?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
